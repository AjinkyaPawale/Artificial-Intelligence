{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify.py : Classify text objects into two categories\n",
    "#\n",
    "# PLEASE PUT YOUR NAMES AND USER IDs HERE\n",
    "#\n",
    "# Based on skeleton code by D. Crandall, March 2021\n",
    "# \n",
    "\n",
    "import sys\n",
    "\n",
    "# Additional libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def load_file(filename):\n",
    "    objects=[]\n",
    "    labels=[]\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            parsed = line.strip().split(' ',1)\n",
    "            labels.append(parsed[0] if len(parsed)>0 else \"\")\n",
    "            objects.append(parsed[1] if len(parsed)>1 else \"\")\n",
    "    \n",
    "    return {\"objects\": objects, \"labels\": labels, \"classes\": list(set(labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "\n",
    "    clean_text = []\n",
    "    spcl= '[-,;@_!#$%^&*()<>?/\\|}{~:''.+\"\"]'\n",
    "    for i in data[\"Tweet\"]:\n",
    "        filtered_tokens=[]\n",
    "        \n",
    "        i = i.lower()\n",
    "        tokens = [word for sent in sent_tokenize(i) for word in word_tokenize(i)]\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token!='':\n",
    "                token = re.sub(spcl,'',token)\n",
    "                token = re.sub('[0-9]','',token)\n",
    "                filtered_tokens.append(token)\n",
    "        v = [word for word in filtered_tokens if word not in stop_words]\n",
    "        temp = ' '.join(w for w in v)\n",
    "        clean_text.append(temp)\n",
    "    data['Clean Text'] = clean_text\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_label_matrix(data):\n",
    "    words_eastcoast = {}\n",
    "    words_westcoast = {}\n",
    "    EastCoast = []\n",
    "    WestCoast = []\n",
    "    eastcoast_df = data[data['Label']=='EastCoast']\n",
    "    westcoast_df = data[data['Label']=='WestCoast']\n",
    "\n",
    "    for i in range(len(eastcoast_df)):\n",
    "        sent = eastcoast_df.iloc[i]['Clean Text'].split(' ')\n",
    "        for w in sent:\n",
    "            if w not in words_eastcoast:\n",
    "                words_eastcoast[w]=1\n",
    "            else:\n",
    "                words_eastcoast[w]+=1\n",
    "                \n",
    "    for i in range(len(westcoast_df)):\n",
    "        sent = westcoast_df.iloc[i]['Clean Text'].split(' ')\n",
    "        for w in sent:\n",
    "            if w not in words_westcoast:\n",
    "                words_westcoast[w]=1\n",
    "            else:\n",
    "                words_westcoast[w]+=1\n",
    "    \n",
    "    return words_eastcoast,words_westcoast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier : Train and apply a bayes net classifier\n",
    "#\n",
    "# This function should take a train_data dictionary that has three entries:\n",
    "#        train_data[\"objects\"] is a list of strings corresponding to documents\n",
    "#        train_data[\"labels\"] is a list of strings corresponding to ground truth labels for each document\n",
    "#        train_data[\"classes\"] is the list of possible class names (always two)\n",
    "#\n",
    "# and a test_data dictionary that has objects and classes entries in the same format as above. It\n",
    "# should return a list of the same length as test_data[\"objects\"], where the i-th element of the result\n",
    "# list is the estimated classlabel for test_data[\"objects\"][i]\n",
    "#\n",
    "# Do not change the return type or parameters of this function!\n",
    "#\n",
    "def classifier(train_data, test_data):\n",
    "    \n",
    "    train_data_df = pd.DataFrame({'Tweet':train_data['objects'], 'Label':train_data['labels']})\n",
    "    train_data_df = clean_data(train_data_df)\n",
    "\n",
    "    test_data_df = pd.DataFrame({'Tweet':test_data['objects']})\n",
    "    test_data_df = clean_data(test_data_df)\n",
    "    \n",
    "    words_eastcoast,words_westcoast = get_words_label_matrix(train_data_df) \n",
    "    \n",
    "    n_eastcoast = len(train_data_df[train_data_df['Label'] == 'EastCoast'])\n",
    "    n_westcoast = len(train_data_df[train_data_df['Label'] == 'WestCoast'])\n",
    "    \n",
    "    p_eastcoast = n_eastcoast/(n_eastcoast+n_westcoast)\n",
    "    p_westcoast = n_westcoast/(n_eastcoast+n_westcoast)\n",
    "    \n",
    "    total_cnts_features_eastcoast = len(words_eastcoast)\n",
    "    total_cnts_features_westcoast = len(words_westcoast)\n",
    "    total_features = len(set(list(words_eastcoast.keys())+list(words_westcoast.keys())))\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(test_data_df)):\n",
    "        probability_word_eastcoast = 1\n",
    "        probability_word_westcoast = 1\n",
    "        sent = test_data_df.iloc[i]['Clean Text'].split(' ')\n",
    "        for word in sent:\n",
    "            if word in words_eastcoast:\n",
    "                p_word_eastcoast = words_eastcoast[word]/len(words_eastcoast)\n",
    "                probability_word_eastcoast = probability_word_eastcoast * p_word_eastcoast\n",
    "            \n",
    "            else:\n",
    "                probability_word_eastcoast = probability_word_eastcoast * (1/(total_cnts_features_eastcoast+total_features))\n",
    "                \n",
    "        for word in sent:\n",
    "            if word in words_westcoast:\n",
    "                p_word_westcoast = words_westcoast[word]/len(words_westcoast)\n",
    "                probability_word_westcoast = probability_word_westcoast * p_word_westcoast\n",
    "            \n",
    "            else:\n",
    "                probability_word_westcoast = probability_word_westcoast * (1/(total_cnts_features_westcoast+total_features))\n",
    "                \n",
    "        posterior_eastcoast = probability_word_eastcoast * p_eastcoast\n",
    "        posterior_westcoast = probability_word_westcoast * p_westcoast\n",
    "        \n",
    "        odds_ratio = posterior_eastcoast / posterior_westcoast\n",
    "        if odds_ratio > 1:\n",
    "            label = \"EastCoast\"\n",
    "        else:\n",
    "            label = \"WestCoast\"\n",
    "        labels.append(label)\n",
    "            \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 84.98%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 3:\n",
    "        raise Exception(\"Usage: classify.py train_file.txt test_file.txt\")\n",
    "\n",
    "    (_, train_file, test_file) = sys.argv\n",
    "    Load in the training and test datasets. The file format is simple: one object\n",
    "    per line, the first word one the line is the label.\n",
    "\n",
    "train_data = load_file(train_file)\n",
    "test_data = load_file(test_file)\n",
    "if(train_data[\"classes\"] != test_data[\"classes\"] or len(test_data[\"classes\"]) != 2):\n",
    "    raise Exception(\"Number of classes should be 2, and must be the same in test and training data\")\n",
    "\n",
    "# make a copy of the test data without the correct labels, so the classifier can't cheat!\n",
    "test_data_sanitized = {\"objects\": test_data[\"objects\"], \"classes\": test_data[\"classes\"]}\n",
    "\n",
    "results= classifier(train_data, test_data_sanitized)\n",
    "\n",
    "# calculate accuracy\n",
    "correct_ct = sum([ (results[i] == test_data[\"labels\"][i]) for i in range(0, len(test_data[\"labels\"])) ])\n",
    "print(\"Classification accuracy = %5.2f%%\" % (100.0 * correct_ct / len(test_data[\"labels\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
